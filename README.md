# YOLO Realâ€‘Time Object Detection (Webcam)

This project gives you **two ways** to run realâ€‘time YOLO detection from your webcam:

1) **CLI (OpenCV window)** â€” easiest for local use  
2) **Streamlit Web App** â€” run in the browser with `streamlit-webrtc`

It uses [Ultralytics YOLOv8](https://github.com/ultralytics/ultralytics) and works on CPU or GPU (CUDA).

---

## 1) Quick Start (CLI)

```bash
# 1) Create and activate a virtual env (Windows PowerShell shown; use python3 on Linux/macOS)
python -m venv .venv
. .venv/Scripts/Activate.ps1   # Windows PowerShell
# source .venv/bin/activate     # Linux/macOS

# 2) Install deps
pip install --upgrade pip
pip install -r requirements.txt

# 3) Run with default COCO model (yolov8n.pt)
python app.py --source 0 --conf 0.35
```

- Press **Q** to quit.  
- Use `--source path/to/video.mp4` for a file instead of webcam.  
- Use `--weights path/to/best.pt` to use your custom model.

---

## 2) Run the Streamlit Web App

```bash
# From your virtual env
streamlit run app_streamlit.py
```
- Allow camera access in the browser.
- Use sliders to change confidence and NMS thresholds live.

---

## Training Custom Model (optional, oneâ€‘liner)

If you have annotated data in YOLO format:
```bash
yolo task=detect mode=train model=yolov8n.pt data=your_data.yaml epochs=50 imgsz=640
```
Then use the trained weights:
```bash
python app.py --weights runs/detect/train/weights/best.pt
```

---

## Files

- `app.py` â€” CLI realâ€‘time detector (OpenCV window)
- `app_streamlit.py` â€” Streamlit realâ€‘time detector (browser), powered by `streamlit-webrtc`
- `requirements.txt` â€” Dependencies
- `README.md` â€” This file

---

## Tips

- **Performance**: Use `yolov8n.pt` for speed; switch to `yolov8s.pt` / `m.pt` for accuracy.  
- **GPU**: If you have CUDA, PyTorch will pick it up automatically once installed.  
- **Save video**: Use `--save out.mp4` on the CLI app to write annotated video.  
- **Tracking**: For simple tracking IDs, use `--track` in the CLI app.

Happy building! ðŸš€